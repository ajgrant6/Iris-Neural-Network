{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0             5.1          3.5           1.4          0.2        0\n",
      "1             4.9          3.0           1.4          0.2        0\n",
      "2             4.7          3.2           1.3          0.2        0\n",
      "3             4.6          3.1           1.5          0.2        0\n",
      "4             5.0          3.6           1.4          0.2        0\n",
      "..            ...          ...           ...          ...      ...\n",
      "145           6.7          3.0           5.2          2.3        2\n",
      "146           6.3          2.5           5.0          1.9        2\n",
      "147           6.5          3.0           5.2          2.0        2\n",
      "148           6.2          3.4           5.4          2.3        2\n",
      "149           5.9          3.0           5.1          1.8        2\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"IRIS.csv\")\n",
    "\n",
    "# Encode the output column\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(data[\"species\"])\n",
    "data[\"species\"] = encoder.transform(data[\"species\"])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into input and target\n",
    "X = data.drop(\"species\", axis = 1).values #.values is needed to convert to np array\n",
    "Y = data[\"species\"].values\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(X, dtype = torch.float32)\n",
    "Y = torch.tensor(Y, dtype = torch.long)\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network\n",
    "\n",
    "class IrisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisModel, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.layer1 = nn.Linear(4, 32)\n",
    "        \n",
    "        self.layer2 = nn.Linear(32, 3)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer2(self.dropout(self.relu(self.layer1(x))))\n",
    "\n",
    "model = IrisModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad() # Reset stored gradients\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "\n",
    "    # Backwards pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 2 | Predicted: 2\n",
      "Expected: 1 | Predicted: 1\n",
      "Expected: 0 | Predicted: 0\n",
      "Expected: 2 | Predicted: 2\n",
      "Expected: 0 | Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    output = model(X_test[i])\n",
    "    _, predicted = torch.max(output, axis = 0)\n",
    "    expected = Y_test[i]\n",
    "    print(f\"Expected: {expected} | Predicted: {predicted.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == Y_test).sum().item() / len(Y_test)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
